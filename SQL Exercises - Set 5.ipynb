{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Notebook Information \"\"\"\n",
    "# References: https://github.com/XD-DENG/SQL-exercise \n",
    "# Workbook Title: PySpark SQL Exercises - Set 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Setup\n",
    "--------------------------------------------\n",
    "#### Installing relevant libraries; Instantiating a PySpark session; Creating a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing libraries \"\"\"\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Instantiate a SparkContext \"\"\"\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "## Print the Spark version\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating a SparkSession \"\"\" \n",
    "spark = SparkSession.builder.appName('JoinsTutorial').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Dataframes\n",
    "--------------------------------------------\n",
    "#### Creating tables as PySpark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Building the schema \"\"\"\n",
    "# Table 1 - Pieces Table \n",
    "data1 = [['HAL','Clarke Enterprises'],\n",
    "        ['RBT','Susan Calvin Corp.'], \n",
    "        ['TNBC','Skellington Supplies']]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['Code', 'Name']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df1 = spark.createDataFrame(data1, columns)\n",
    "\n",
    "# Table 2 - Providers Table \n",
    "data2 = [[1,'Sprocket'],\n",
    "         [2,'Screw'],\n",
    "         [3,'Nut'],\n",
    "         [4,'Bolt']]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['Code', 'Name']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df2 = spark.createDataFrame(data2, columns)\n",
    "\n",
    "# Table 3 - Provides Table \n",
    "data3 = [[1,'HAL',10],\n",
    "         [1,'RBT',15],\n",
    "         [2,'HAL',20],\n",
    "         [2,'RBT',15],\n",
    "         [2,'TNBC',14],\n",
    "         [3,'RBT',50],\n",
    "         [3,'TNBC',45],\n",
    "         [4,'HAL',5],\n",
    "         [4,'RBT',7]]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['Piece', 'Provider', 'Price']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df3 = spark.createDataFrame(data3, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating Temporary Tables to be used in spark.sql \"\"\"\n",
    "## setting temporary views by creating dataframes\n",
    "# creating a view for df1 named Manufacturers\n",
    "df1.createOrReplaceTempView(\"Pieces\")\n",
    "  \n",
    "# creating a view for df2 named Providers\n",
    "df2.createOrReplaceTempView(\"Providers\")\n",
    "\n",
    "# creating a view for df2 named Provides\n",
    "df3.createOrReplaceTempView(\"Provides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries - Set 5\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|Code|Name                |\n",
      "+----+--------------------+\n",
      "|HAL |Clarke Enterprises  |\n",
      "|RBT |Susan Calvin Corp.  |\n",
      "|TNBC|Skellington Supplies|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Checking the Pieces table \"\"\"\n",
    "\n",
    "# -- Checking the first 5 records of the Pieces table \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Pieces\n",
    "        LIMIT 5\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Code|Name    |\n",
      "+----+--------+\n",
      "|1   |Sprocket|\n",
      "|2   |Screw   |\n",
      "|3   |Nut     |\n",
      "|4   |Bolt    |\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Checking the Providers table \"\"\"\n",
    "\n",
    "# -- Checking the first 5 records of the Providers table \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Providers\n",
    "        LIMIT 5\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+\n",
      "|Piece|Provider|Price|\n",
      "+-----+--------+-----+\n",
      "|1    |HAL     |10   |\n",
      "|1    |RBT     |15   |\n",
      "|2    |HAL     |20   |\n",
      "|2    |RBT     |15   |\n",
      "|2    |TNBC    |14   |\n",
      "+-----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Checking the Provides table \"\"\"\n",
    "\n",
    "# -- Checking the first 5 records of the Provides table \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Provides\n",
    "        LIMIT 5\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Name                |\n",
      "+--------------------+\n",
      "|Susan Calvin Corp.  |\n",
      "|Clarke Enterprises  |\n",
      "|Skellington Supplies|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.1 \"\"\"\n",
    "\n",
    "# -- Get the name of all the pieces \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT DISTINCT Name\n",
    "        FROM Pieces\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Provider|\n",
      "+--------+\n",
      "|HAL     |\n",
      "|TNBC    |\n",
      "|RBT     |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.2 \"\"\"\n",
    "\n",
    "# -- Get the name of the providers\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT DISTINCT Provider\n",
    "        FROM Provides\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Piece|Average_price     |\n",
      "+-----+------------------+\n",
      "|1    |12.5              |\n",
      "|3    |47.5              |\n",
      "|2    |16.333333333333332|\n",
      "|4    |6.0               |\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.3 \"\"\"\n",
    "\n",
    "# -- Get the average price of each piece (show only the piece code and the average price)\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Piece, AVG(Price) AS Average_price\n",
    "        FROM Provides\n",
    "        Group BY Piece\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Name    |\n",
      "+--------+\n",
      "|Sprocket|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.4 - Subquery Approach \"\"\"\n",
    "\n",
    "# -- Get the name of all providers who will supply piece number 1\n",
    "\n",
    "# Note: This can be solved using a join approach or a subquery approach \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT DISTINCT Name\n",
    "        FROM Providers \n",
    "        WHERE Code IN (SELECT Piece\n",
    "                       FROM Provides\n",
    "                       WHERE Piece = 1)\n",
    "\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Name    |\n",
      "+--------+\n",
      "|Sprocket|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.4 - Join Approach \"\"\"\n",
    "\n",
    "# -- Get the name of all providers who will supply piece number 1\n",
    "\n",
    "# Note: This can be solved using a join approach or a subquery approach \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT DISTINCT Name\n",
    "        FROM Providers AS A INNER JOIN Provides AS B ON A.Code = B.Piece\n",
    "        WHERE B.Piece = 1\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Name    |\n",
      "+--------+\n",
      "|Sprocket|\n",
      "|Screw   |\n",
      "|Bolt    |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.5 - Subquery Approach \"\"\"\n",
    "\n",
    "# -- Select the name of pieces provided by provider with code \"HAL\".\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Name\n",
    "        FROM Providers\n",
    "        WHERE Code IN (SELECT Piece\n",
    "                       FROM Provides\n",
    "                       WHERE Provider = 'HAL')\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Name    |\n",
      "+--------+\n",
      "|Sprocket|\n",
      "|Screw   |\n",
      "|Bolt    |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.5 - Subquery Approach \"\"\"\n",
    "\n",
    "# -- Select the name of pieces provided by provider with code \"HAL\".\n",
    "# Note: Two table are needed for this - Providers and Provides \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Name\n",
    "        FROM Providers AS A INNER JOIN Provides AS B ON A.Code = B.Piece\n",
    "        WHERE B.Provider = 'HAL'\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+--------+-----+----+------------------+\n",
      "|Code|Name|Piece|Provider|Price|Code|Name              |\n",
      "+----+----+-----+--------+-----+----+------------------+\n",
      "|3   |Nut |3    |RBT     |50   |RBT |Susan Calvin Corp.|\n",
      "+----+----+-----+--------+-----+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Query 5.6 \"\"\" # Look into this again \n",
    "\n",
    "# -- For each piece, find the most expensive offering of that piece and include the piece name, provider name, and price \n",
    "\n",
    "# Note: Tables needed Pieces, Provider and Provides\n",
    "\n",
    "# Step 1: Get the master table that includes the pieces, provider and provides columns\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Providers AS A INNER JOIN Provides AS B ON A.Code = B.Piece\n",
    "                            INNER JOIN Pieces AS C ON B.Provider = C.Code\n",
    "        WHERE Price = (SELECT MAX(Price)\n",
    "                       FROM Provides)\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7e022b67859ae4a791bbcc1c75bde8b3a5bef3b9abb0060fdb4399d638fb2f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

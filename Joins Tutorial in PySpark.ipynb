{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Notebook Information '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Notebook Information \"\"\"\n",
    "# References: https://www.geeksforgeeks.org/pyspark-join-types-join-two-dataframes/\n",
    "# Workbook Title: PySpark Joins Tutorial - PySpark and SQL syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Setup\n",
    "--------------------------------------------\n",
    "#### Installing relevant libraries; Instantiating a PySpark session; Creating a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing libraries \"\"\"\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Instantiate a SparkContext \"\"\"\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "## Print the Spark version\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating a SparkSession \"\"\" \n",
    "spark = SparkSession.builder.appName('JoinsTutorial').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Dataframes\n",
    "--------------------------------------------\n",
    "#### Creating tables as PySpark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating employees table \"\"\"\n",
    "# list  of employee data\n",
    "data1 = [[\"1\", \"sravan\", \"company 1\"],\n",
    "        [\"2\", \"ojaswi\", \"company 1\"], \n",
    "        [\"3\", \"rohith\", \"company 2\"],\n",
    "        [\"4\", \"sridevi\", \"company 1\"], \n",
    "        [\"5\", \"bobby\", \"company 1\"]]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['ID', 'Name', 'Company']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df1 = spark.createDataFrame(data1, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating department table \"\"\"\n",
    "# list  of employee data\n",
    "data2 = [[\"1\", \"45000\", \"IT\"],\n",
    "         [\"2\", \"145000\", \"Manager\"],\n",
    "         [\"6\", \"45000\", \"HR\"],\n",
    "         [\"5\", \"34000\", \"Sales\"]]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['ID', 'Salary', 'Department']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df2 = spark.createDataFrame(data2, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+\n",
      "|ID |Name   |Company  |\n",
      "+---+-------+---------+\n",
      "|1  |sravan |company 1|\n",
      "|2  |ojaswi |company 1|\n",
      "|3  |rohith |company 2|\n",
      "|4  |sridevi|company 1|\n",
      "|5  |bobby  |company 1|\n",
      "+---+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Checking the PySpark dataframe \"\"\"\n",
    "# checking the dataframe  - Employees Table \n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+\n",
      "|ID |Salary|Department|\n",
      "+---+------+----------+\n",
      "|1  |45000 |IT        |\n",
      "|2  |145000|Manager   |\n",
      "|6  |45000 |HR        |\n",
      "|5  |34000 |Sales     |\n",
      "+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Checking the PySpark dataframe \"\"\"\n",
    "# checking the dataframe - Department Table\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Joins\n",
    "--------------------------------------------\n",
    "#### Creating various joins (Full, Left, Right and Inner) using PySpark syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+---+------+----------+\n",
      "|ID |Name  |Company  |ID |Salary|Department|\n",
      "+---+------+---------+---+------+----------+\n",
      "|5  |bobby |company 1|5  |34000 |Sales     |\n",
      "|1  |sravan|company 1|1  |45000 |IT        |\n",
      "|2  |ojaswi|company 1|2  |145000|Manager   |\n",
      "+---+------+---------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 1 - Inner Join example \"\"\"\n",
    "df1.join(df2, df1.ID == df2.ID, \"inner\").show(truncate=False) # Inner joining df2 based on the ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+----+------+----------+\n",
      "|ID  |Name   |Company  |ID  |Salary|Department|\n",
      "+----+-------+---------+----+------+----------+\n",
      "|3   |rohith |company 2|null|null  |null      |\n",
      "|5   |bobby  |company 1|5   |34000 |Sales     |\n",
      "|null|null   |null     |6   |45000 |HR        |\n",
      "|1   |sravan |company 1|1   |45000 |IT        |\n",
      "|4   |sridevi|company 1|null|null  |null      |\n",
      "|2   |ojaswi |company 1|2   |145000|Manager   |\n",
      "+----+-------+---------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 2 - Full Join example \"\"\"\n",
    "df1.join(df2, df1.ID == df2.ID, \"full\").show(truncate=False) # Full joining df2 based on the ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+----+------+----------+\n",
      "|ID |Name   |Company  |ID  |Salary|Department|\n",
      "+---+-------+---------+----+------+----------+\n",
      "|3  |rohith |company 2|null|null  |null      |\n",
      "|5  |bobby  |company 1|5   |34000 |Sales     |\n",
      "|1  |sravan |company 1|1   |45000 |IT        |\n",
      "|4  |sridevi|company 1|null|null  |null      |\n",
      "|2  |ojaswi |company 1|2   |145000|Manager   |\n",
      "+---+-------+---------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 3 - Left Join example \"\"\"\n",
    "df1.join(df2, df1.ID == df2.ID, \"left\").show(truncate=False) # Left joining df2 based on the ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+---+------+----------+\n",
      "|ID  |Name  |Company  |ID |Salary|Department|\n",
      "+----+------+---------+---+------+----------+\n",
      "|5   |bobby |company 1|5  |34000 |Sales     |\n",
      "|null|null  |null     |6  |45000 |HR        |\n",
      "|1   |sravan|company 1|1  |45000 |IT        |\n",
      "|2   |ojaswi|company 1|2  |145000|Manager   |\n",
      "+----+------+---------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 4 - Right join example \"\"\"\n",
    "df1.join(df2, df1.ID == df2.ID, \"right\").show(truncate=False) # Right joining df2 on df2 based on the ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Tables Setup in PySpark\n",
    "--------------------------------------------\n",
    "#### Creating Temporary Tables for spark.sql - these tables will be used for SQL quering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating Temporary Tables to be used in spark.sql \"\"\"\n",
    "## setting temporary views by creating dataframes\n",
    "# creating a view for df1 named employees\n",
    "df1.createOrReplaceTempView(\"Employees\")\n",
    "  \n",
    "# creating a view for df2 named department\n",
    "df2.createOrReplaceTempView(\"Department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Queries in PySpark\n",
    "--------------------------------------------\n",
    "#### Queries: SELECT; FROM; WHERE; GROUP BY; HAVING; IN; ORDER BY; Aggregate functions: AVG, MAX, MIN; Joins: Full, Left, Right, Inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+------+\n",
      "|ID |NAME   |Department|Salary|\n",
      "+---+-------+----------+------+\n",
      "|3  |rohith |null      |null  |\n",
      "|5  |bobby  |Sales     |34000 |\n",
      "|1  |sravan |IT        |45000 |\n",
      "|4  |sridevi|null      |null  |\n",
      "|2  |ojaswi |Manager   |145000|\n",
      "+---+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 5 - Inner Join based on ID \"\"\"\n",
    "query = \"SELECT E.ID, E.NAME, D.Department, D.Salary FROM Employees AS E LEFT JOIN Department AS D on E.ID == D.ID\" # Selecting columns from different tables and merging two tables using a left join\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+----+------+----------+\n",
      "|ID |Name   |Company  |ID  |Salary|Department|\n",
      "+---+-------+---------+----+------+----------+\n",
      "|3  |rohith |company 2|null|null  |null      |\n",
      "|5  |bobby  |company 1|5   |34000 |Sales     |\n",
      "|1  |sravan |company 1|1   |45000 |IT        |\n",
      "|4  |sridevi|company 1|null|null  |null      |\n",
      "|2  |ojaswi |company 1|2   |145000|Manager   |\n",
      "+---+-------+---------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 6 - Left Join based on ID \"\"\"\n",
    "query = \"SELECT * FROM Employees AS E LEFT JOIN Department as D on E.ID == D.ID\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+---+------+----------+\n",
      "|ID  |Name  |Company  |ID |Salary|Department|\n",
      "+----+------+---------+---+------+----------+\n",
      "|5   |bobby |company 1|5  |34000 |Sales     |\n",
      "|null|null  |null     |6  |45000 |HR        |\n",
      "|1   |sravan|company 1|1  |45000 |IT        |\n",
      "|2   |ojaswi|company 1|2  |145000|Manager   |\n",
      "+----+------+---------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 7 - Right Join based on ID \"\"\"\n",
    "query = \"SELECT * FROM Employees AS E RIGHT JOIN Department AS D ON E.ID == D.ID\"\n",
    "\n",
    "spark.sql(query).show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+----+------+----------+\n",
      "|ID  |Name   |Company  |ID  |Salary|Department|\n",
      "+----+-------+---------+----+------+----------+\n",
      "|3   |rohith |company 2|null|null  |null      |\n",
      "|5   |bobby  |company 1|5   |34000 |Sales     |\n",
      "|null|null   |null     |6   |45000 |HR        |\n",
      "|1   |sravan |company 1|1   |45000 |IT        |\n",
      "|4   |sridevi|company 1|null|null  |null      |\n",
      "|2   |ojaswi |company 1|2   |145000|Manager   |\n",
      "+----+-------+---------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example 8 - Full Join based on ID \"\"\"\n",
    "query = \"SELECT * FROM Employees AS E FULL JOIN Department AS D ON E.ID == D.ID\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+\n",
      "|ID |Salary|Department|\n",
      "+---+------+----------+\n",
      "|6  |45000 |HR        |\n",
      "|5  |34000 |Sales     |\n",
      "|1  |45000 |IT        |\n",
      "+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query \"\"\" # SELECT FROM WHERE IN \n",
    "query = \"SELECT * FROM Department WHERE ID IN (1,5,6) ORDER BY ID DESC\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+\n",
      "|ID |Name |Company  |\n",
      "+---+-----+---------+\n",
      "|5  |bobby|company 1|\n",
      "+---+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query \"\"\" # SELECT FROM WHERE \n",
    "query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM Employees \n",
    "        WHERE NAME == \"bobby\"     \n",
    "        \"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Department|Avg_Salary|\n",
      "+----------+----------+\n",
      "|Sales     |34000.0   |\n",
      "|HR        |45000.0   |\n",
      "|IT        |45000.0   |\n",
      "|Manager   |145000.0  |\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query \"\"\" # GROUP BY\n",
    "\n",
    "# Find the average salary per department \n",
    "query = \"\"\"\n",
    "        SELECT Department, AVG(Salary) AS Avg_Salary\n",
    "        FROM Department\n",
    "        GROUP BY Department \n",
    "        \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Department|Avg_Salary|\n",
      "+----------+----------+\n",
      "|Manager   |145000.0  |\n",
      "|HR        |45000.0   |\n",
      "|IT        |45000.0   |\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query using GROUP BY & ORDER BY \"\"\" \n",
    "\n",
    "# Find the average salary per department and sort this based on the top 3 most paid departments \n",
    "query = \"\"\"\n",
    "        SELECT Department, AVG(Salary) AS Avg_Salary\n",
    "        FROM Department \n",
    "        GROUP BY Department\n",
    "        ORDER BY Avg_Salary DESC\n",
    "        LIMIT 3\n",
    "        \"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+\n",
      "|Department|Avg_Salary|Max_Salary|Min_Salary|\n",
      "+----------+----------+----------+----------+\n",
      "|Sales     |34000.0   |34000     |34000     |\n",
      "|HR        |45000.0   |45000     |45000     |\n",
      "|IT        |45000.0   |45000     |45000     |\n",
      "|Manager   |145000.0  |145000    |145000    |\n",
      "+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query using AVG MAX MIN and GROUP BY \"\"\"\n",
    "\n",
    "# Find the average salary per department along with their minimum and maximum salary per department \n",
    "query = \"\"\"\n",
    "        SELECT Department, AVG(Salary) AS Avg_Salary, MAX(Salary) AS Max_Salary, MIN(Salary) AS Min_Salary\n",
    "        FROM Department \n",
    "        GROUP BY Department\n",
    "        \"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Avg_Salary|\n",
      "+----------+\n",
      "|145000.0  |\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query \"\"\"\n",
    "\n",
    "# Print the average salary earned as a manager \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT AVG(Salary) AS Avg_Salary\n",
    "        FROM Department \n",
    "        WHERE Department = 'Manager'\n",
    "        \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+\n",
      "|ID |NAME  |Department|Salary|\n",
      "+---+------+----------+------+\n",
      "|5  |bobby |Sales     |34000 |\n",
      "|1  |sravan|IT        |45000 |\n",
      "|2  |ojaswi|Manager   |145000|\n",
      "+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example - SQL Query \"\"\" \n",
    "\n",
    "# Print all employees that have a salary\n",
    "\n",
    "\"\"\" Example 5 - Inner Join based on ID \"\"\"\n",
    "query = \"SELECT E.ID, E.NAME, D.Department, D.Salary FROM Employees AS E LEFT JOIN Department AS D on E.ID == D.ID WHERE Salary IS NOT NULL\" # Selecting columns from different tables and merging two tables using a left join\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+\n",
      "|ID |NAME  |Department|Salary|\n",
      "+---+------+----------+------+\n",
      "|5  |bobby |Sales     |34000 |\n",
      "|1  |sravan|IT        |45000 |\n",
      "|2  |ojaswi|Manager   |145000|\n",
      "+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Concatenating the SQL query in a variable \"\"\"\n",
    "df = spark.sql(query) # Note: If you want to change a PySpark dataframe to a Pandas dataframe you need to remvoe the .show(truncate=False) at the end - spark.sql(query) concatenates the pyspark dataframe and converts it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From PySpark Dataframe to Pandas Dataframe\n",
    "--------------------------------------------\n",
    "#### Converting PySpark Dataframe into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Converting Spark dataframe to Pandas dataframe \"\"\"\n",
    "pandasDF = spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>bobby</td>\n",
       "      <td>Sales</td>\n",
       "      <td>34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sravan</td>\n",
       "      <td>IT</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ojaswi</td>\n",
       "      <td>Manager</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID    NAME Department  Salary\n",
       "0  5   bobby      Sales   34000\n",
       "1  1  sravan         IT   45000\n",
       "2  2  ojaswi    Manager  145000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Checking the Pandas Dataframe \"\"\"\n",
    "pandasDF.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

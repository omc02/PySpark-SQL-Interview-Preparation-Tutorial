{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Notebook Information \"\"\"\n",
    "# References: https://github.com/XD-DENG/SQL-exercise ; https://en.wikibooks.org/wiki/SQL_Exercises/The_computer_store\n",
    "# Workbook Title: PySpark SQL Exercises - Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Setup\n",
    "--------------------------------------------\n",
    "#### Installing relevant libraries; Instantiating a PySpark session; Creating a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing libraries \"\"\"\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Instantiate a SparkContext \"\"\"\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "## Print the Spark version\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating a SparkSession \"\"\" \n",
    "spark = SparkSession.builder.appName('JoinsTutorial').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Dataframes\n",
    "--------------------------------------------\n",
    "#### Creating tables as PySpark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Building the schema \"\"\"\n",
    "# Table 1 - Manufacturers Table \n",
    "data1 = [[14,'IT',65000],\n",
    "        [37,'Accounting',15000], \n",
    "        [59,'Human Resources',240000],\n",
    "        [77,'Research',55000]]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['Code', 'Name', 'Budget']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df1 = spark.createDataFrame(data1, columns)\n",
    "\n",
    "# Table 2 - Products Table \n",
    "data2 = [[123234877,'Michael','Rogers',14],\n",
    "         [152934485,'Anand','Manikutty',14],\n",
    "         [222364883,'Carol','Smith',37],\n",
    "         [326587417,'Joe','Stevens',37],\n",
    "         [332154719,'Mary-Anne','Foster',14],\n",
    "         [332569843,'George','ODonnell',77],\n",
    "         [546523478,'John','Doe',59],\n",
    "         [631231482,'David','Smith',77],\n",
    "         [654873219,'Zacary','Efron',59],\n",
    "         [745685214,'Eric','Goldsmith',59],\n",
    "         [845657245,'Elizabeth','Doe',14],\n",
    "         [845657246,'Kumar','Swamy',14]]\n",
    "  \n",
    "# specify column names\n",
    "columns = ['SSN', 'Name', 'LastName', 'Department']\n",
    "  \n",
    "# creating a df1 from the lists of data\n",
    "df2 = spark.createDataFrame(data2, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating Temporary Tables to be used in spark.sql \"\"\"\n",
    "## setting temporary views by creating dataframes\n",
    "# creating a view for df1 named Manufacturers\n",
    "df1.createOrReplaceTempView(\"Departments\")\n",
    "  \n",
    "# creating a view for df2 named Products\n",
    "df2.createOrReplaceTempView(\"Employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Checking the column types for Table 1 - Departments \"\"\"\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Checking the column types for Table 2 - Employees \"\"\"\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Checking the tables \"\"\" \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Departments\n",
    "        LIMIT 3\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Checking the tables \"\"\" \n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Employees\n",
    "        LIMIT 5\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries - Set 2\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.1 \"\"\"\n",
    "\n",
    "# -- 2.1 Select the last name of all employees.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT LastName\n",
    "        FROM Employees\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.2 \"\"\"\n",
    "\n",
    "# -- 2.2 Select the last name of all unique employees, without duplicates.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT DISTINCT LastName\n",
    "        FROM Employees\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.3 \"\"\"\n",
    "\n",
    "# -- 2.3 Select all the data of employees whose last name is \"Smith\".\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Employees\n",
    "        WHERE LastName = \"Smith\"\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.4 \"\"\"\n",
    "\n",
    "# -- 2.4 Select all the data of employees whose last name is \"Smith\" or \"Doe\".\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Employees\n",
    "        WHERE LastName IN (\"Smith\",\"Doe\")\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.5 \"\"\"\n",
    "\n",
    "# -- 2.5 Select all the data of employees that work in department 14.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Employees\n",
    "        WHERE Department = '14'\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.6 \"\"\"\n",
    "\n",
    "# -- 2.6 Select all the data of employees that work in department 37 or department 77.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Employees\n",
    "        WHERE Department IN (37,77)\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.7 \"\"\"\n",
    "\n",
    "# -- 2.7 Select all the data of employees whose last name begins with an \"S\".\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Employees\n",
    "        WHERE LastName LIKE 'S%'\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.8 \"\"\"\n",
    "\n",
    "# -- 2.8 Select the sum of all the departments' budgets.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Name AS Department_name, SUM(Budget) AS Department_budget\n",
    "        FROM Departments\n",
    "        GROUP BY Name\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.9 \"\"\"\n",
    "\n",
    "# -- 2.9 Select the number of employees in each department (you only need to show the department code and the number of employees).\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Name AS Department_name, SUM(Budget) AS Department_budget\n",
    "        FROM Departments\n",
    "        GROUP BY Name\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.10 \"\"\"\n",
    "\n",
    "# -- 2.10 Select all the data of employees, including each employee's department's data.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *, B.Name AS Department_name, Budget AS Department_budget\n",
    "        FROM Employees AS A INNER JOIN Departments AS B ON A.Department = B.Code\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.11 \"\"\"\n",
    "\n",
    "# -- 2.11 Select the name and last name of each employee, along with the name and budget of the employee's department.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT A.Name AS FirstName, A.LastName, B.Name AS Department_name, B.Budget AS Department_budget\n",
    "        FROM Employees AS A INNER JOIN Departments AS B ON A.Department = B.Code\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.12 \"\"\"\n",
    "\n",
    "# -- 2.12 Select the name and last name of employees working for departments with a budget greater than $60,000.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT A.Name AS FirstName, A.LastName, B.Name AS Department_name, B.Budget AS Department_budget\n",
    "        FROM Employees AS A INNER JOIN Departments AS B ON A.Department = B.Code\n",
    "        WHERE B.Budget > 60000\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.13 \"\"\"\n",
    "\n",
    "# -- 2.13 Select the departments with a budget larger than the average budget of all the departments.\n",
    "\n",
    "# Creating the sub-query\n",
    "sub_query = \"\"\"\n",
    "        SELECT AVG(Budget) AS Average_budget\n",
    "        FROM Departments\n",
    "       \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Departments\n",
    "        WHERE Budget > (SELECT AVG(Budget) AS Average_budget\n",
    "                      FROM Departments)\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.14 - Subquery Approach \"\"\"\n",
    "\n",
    "# -- 2.14 Select the names of departments with more than two employees.\n",
    "\n",
    "# Creating the sub-query to get the departments that have more than two employees \n",
    "\n",
    "# Step 1: Getting the employees that work in more than one department\n",
    "sub_query = \"\"\"\n",
    "        SELECT Department\n",
    "        FROM Employees\n",
    "        GROUP BY Department\n",
    "        HAVING COUNT(*) > 2\n",
    "        \"\"\"\n",
    "\n",
    "# Step 2: Getting the departments name that have a code which falls in the range of departments with more than 2 employees \n",
    "query = \"\"\"\n",
    "        SELECT Name\n",
    "        FROM Departments\n",
    "        WHERE Code IN ( SELECT Department\n",
    "                        FROM Employees\n",
    "                        GROUP BY Department\n",
    "                        HAVING COUNT(*) > 2 )\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.14 - Join Approach \"\"\" \n",
    "\n",
    "# -- 2.14 Select the names of departments with more than two employees.\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT B.Name AS Department_name\n",
    "        FROM Employees AS A INNER JOIN Departments AS B ON A.Department = B.Code\n",
    "        GROUP BY B.Name\n",
    "        HAVING COUNT(*)>2\n",
    "       \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.15 - Subquery Approach \"\"\"\n",
    "\n",
    "# -- 2.15 Select the name and last name of employees working for departments with second lowest budget.\n",
    "\n",
    "# Step 1: Getting all the columns in the departments table with the two lowest budgets \n",
    "query1 = \"\"\"\n",
    "        SELECT *\n",
    "        FROM Departments\n",
    "        ORDER BY Budget\n",
    "        LIMIT 2\n",
    "        \"\"\"\n",
    "\n",
    "# Step 2: Getting the department codes of two lowest departments\n",
    "query2 = \"\"\"\n",
    "        SELECT Code\n",
    "        FROM (SELECT *\n",
    "              FROM Departments\n",
    "              ORDER BY Budget\n",
    "              LIMIT 2)\n",
    "        \"\"\"\n",
    "\n",
    "# Step 3: Getting the name and last name of the employees from the codes while ordering by the greatest budget of these two and taking the first observation of these two\n",
    "query = \"\"\"\n",
    "        SELECT E.Name, E.LastName\n",
    "        FROM Employees AS E\n",
    "        WHERE Department IN (SELECT Code\n",
    "                             FROM (SELECT *\n",
    "                                   FROM Departments\n",
    "                                   ORDER BY Budget\n",
    "                                   LIMIT 2) AS D\n",
    "                             ORDER BY D.Budget DESC LIMIT 1)\n",
    "        \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Query 2.16 - CASE \"\"\"\n",
    "\n",
    "# -- 2.16 Create a new column which adds the name for each department as per the following IT, Accounting, Research and Human Resources for Departments 14, 37, 77 and 59\n",
    "query = \"\"\"\n",
    "        SELECT  E.SSN, E.Name AS First_name, E.LastName AS Last_name, E.Department, \n",
    "        CASE \n",
    "                WHEN E.Department = 14 THEN 'IT'\n",
    "                WHEN E.Department = 37 THEN 'Accounting'\n",
    "                WHEN E.Department = 59 THEN 'Human Resources'\n",
    "                WHEN E.Department = 77 THEN 'Research'\n",
    "                END AS Department_name\n",
    "        FROM Employees AS E \n",
    "        \"\"\"\n",
    "\n",
    "spark.sql(query).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6368a34afb731bb0f841c9450d2a8e61658b3b17cc345702a1e169cc2d30af5c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
